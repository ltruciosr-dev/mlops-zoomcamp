{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04-deployment\n",
    "\n",
    "We'll deploy the ride duration model in `batch` mode, and we will use the **Yellow Taxi Trip Records** dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Notebook\n",
    "\n",
    "What's the standard deviation of the predicted duration for the dataset of **March 2023**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.bin', 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2023'\n",
    "month = '03'\n",
    "df = read_data(f'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{month}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = df[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(dicts)\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6.247488852238703)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Preparing the output\n",
    "\n",
    "First, let's create an artificial `ride_id` column, then, write the `ride_id` and the `predictions` to a dataframe with results and store it as parquet datafile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2023\n",
    "month = 3\n",
    "df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df[['ride_id']].copy()\n",
    "df_result['predictions'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = f'predictions/predictions_yellow_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "df_result.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--. 1 ltruciosr-dev ltruciosr-dev 66M Jun 28 13:48 predictions/predictions_yellow_tripdata_2023-03.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {output_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Creating the scoring script\n",
    "\n",
    "Now let's put everything into a virtual environment by creating two files `Pipfile` and `Pipfile.lock`. \n",
    "\n",
    "The `Pipfile.lock` file keeps the hashes of the dependencies we use for the virtual env."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow this steps:\n",
    "\n",
    "1. Create a new pipenv inside the project\n",
    "\n",
    "```bash\n",
    "    pipenv --python 3.x\n",
    "```\n",
    "\n",
    "2. Add dependencies and modify according to the current project\n",
    "\n",
    "```bash\n",
    "    [[source]]\n",
    "    url = \"https://pypi.org/simple\"\n",
    "    verify_ssl = true\n",
    "    name = \"pypi\"\n",
    "\n",
    "    [packages]\n",
    "    scikit-learn = \"==1.5.0\"\n",
    "    pandas = \"==2.2.2\"\n",
    "\n",
    "    [dev-packages]\n",
    "\n",
    "    [requires]\n",
    "    python_version = \"3.10\"\n",
    "    python_full_version = \"3.10.14\"\n",
    "\n",
    "```\n",
    "\n",
    "3. Generate the lock file\n",
    "\n",
    "```bash\n",
    "    pipenv lock\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
